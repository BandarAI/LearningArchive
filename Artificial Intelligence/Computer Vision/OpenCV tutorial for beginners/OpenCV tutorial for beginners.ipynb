{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Turotial from https://www.youtube.com/watch?v=eDIj5LuIL4A&t=569s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import cv2 as cv\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image \n",
    "import os\n",
    "\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 1: what are images?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = cv2.imread('cat.jpg')\n",
    "# print(type(img))\n",
    "# print(\"h,w,dim\",img.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 2: input/output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = r'\\opencv_beginners_tutorial'\n",
    "\n",
    "# image_path = os.path.join(path, 'cat.jpg')\n",
    "# img = cv2.imread(image_path)\n",
    "# cv2.imwrite(os.path.join(path, 'cat_out.jpg'), img)\n",
    "# # cv2.imshow('image', img)\n",
    "# # cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vid_path = os.path.join(path, 'cat.gif')\n",
    "# vid = cv2.VideoCapture(vid_path)\n",
    "# ret = True\n",
    "# while ret:\n",
    "#     ret, frame = vid.read()\n",
    "\n",
    "#     if ret:\n",
    "#         cv2.imshow('frame', frame)\n",
    "#         cv2.waitKey(0)\n",
    "#         vid.release()\n",
    "#         cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [],
   "source": [
    "# webcam = cv2.VideoCapture(2)\n",
    "\n",
    "# while True:\n",
    "#     ret, frame = webcam.read()\n",
    "\n",
    "#     cv2.imshow('frame', frame)\n",
    "#     if cv2.waitKey(40) & 0xFF == ord('q'):\n",
    "#         break\n",
    "\n",
    "# webcam.release()\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 3: basic operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = cv2.imread(os.path.join('.', 'cat.jpg'))\n",
    "\n",
    "# print(\"original img shape\", img.shape)\n",
    "\n",
    "# cv.imshow(\"img\", img)\n",
    "# cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resized = cv.resize(img, (300,300))\n",
    "\n",
    "# print(\"resized img shape\", resized.shape)\n",
    "# cv.imshow(\"resized img\", resized)\n",
    "# cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = cv2.imread(os.path.join('.', 'cat.jpg'))\n",
    "\n",
    "# crop = img[:,400:1100]\n",
    "\n",
    "# cv.imshow(\"img\", crop)\n",
    "# cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 4: Colorspaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = cv2.imread(os.path.join('.', 'cat.jpg'))\n",
    "\n",
    "# bgr2gry = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "# cv.imshow(\"bgr2gry\", bgr2gry)\n",
    "# cv.imshow(\"img\", img)\n",
    "# cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 5: blurring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = cv2.imread(os.path.join('.', 'cat.jpg'))\n",
    "\n",
    "# k = 11\n",
    "# blur = cv.blur(img, (k,k))\n",
    "# gaussianblur = cv.GaussianBlur(img, (k,k), 5)\n",
    "# medianblur = cv.medianBlur(img, k)\n",
    "\n",
    "# cv.imshow(\"medianBlur\", medianblur)\n",
    "# cv.imshow(\"gaussianblur\", gaussianblur)\n",
    "# cv.imshow(\"blur\", blur)\n",
    "# cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 6: threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = cv2.imread(os.path.join('.', 'cat.jpg'))\n",
    "\n",
    "# img2gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "# ret, threshold = cv.threshold(img2gray, 80, 255,cv.THRESH_BINARY)\n",
    "\n",
    "\n",
    "# cv.imshow(\"img2gray\", img2gray)\n",
    "# cv.imshow(\"threshold\", threshold)\n",
    "\n",
    "# cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 7: edge detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = cv2.imread(os.path.join('.', 'cat.jpg'))\n",
    "\n",
    "# canny = cv.Canny(img, 200, 200)\n",
    "\n",
    "# dil = cv.dilate(canny, np.ones((7,7), dtype=np.int8))\n",
    "# erode = cv.erode(dil, np.ones((2,2), dtype=np.int8))\n",
    "\n",
    "# cv.imshow(\"erode\", erode)\n",
    "# cv.imshow(\"dil\", dil)\n",
    "# cv.imshow(\"canny\", canny)\n",
    "# cv.imshow(\"img\", img)\n",
    "\n",
    "# cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 8: drawing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = cv2.imread(os.path.join('.', 'cat.jpg'))\n",
    "\n",
    "# # cv.line(img, (100,150), (0, 0), (0,255,0), 3)\n",
    "# # cv.rectangle(img, (100,150), (0, 0), (0,255,0), 3)\n",
    "# # cv.circle(img, (100,150), 15, (0,255,0), 3)\n",
    "# cv.putText(img, 'hello', (800,450), cv.FONT_HERSHEY_SIMPLEX, 2 ,(255,255,0), 2)\n",
    "\n",
    "\n",
    "# cv.imshow(\"img\", img)\n",
    "# cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 9: Contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# import cv2\n",
    "\n",
    "\n",
    "# img = cv2.imread(os.path.join('.', 'birds.jpg'))\n",
    "\n",
    "# img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# ret, thresh = cv2.threshold(img_gray, 127, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "# contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# for cnt in contours:\n",
    "#     if cv2.contourArea(cnt) > 200:\n",
    "#         # cv2.drawContours(img, cnt, -1, (0, 255, 0), 1)\n",
    "\n",
    "#         x1, y1, w, h = cv2.boundingRect(cnt)\n",
    "\n",
    "#         cv2.rectangle(img, (x1, y1), (x1 + w, y1 + h), (0, 255, 0), 2)\n",
    "\n",
    "# cv2.imshow('img', img)\n",
    "# cv2.imshow('thresh', thresh)\n",
    "# cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1: Color detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_limits(color):\n",
    "#     c = np.uint8([[color]])  # BGR values\n",
    "#     hsvC = cv2.cvtColor(c, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "#     hue = hsvC[0][0][0]  # Get the hue value\n",
    "\n",
    "#     # Handle red hue wrap-around\n",
    "#     if hue >= 165:  # Upper limit for divided red hue\n",
    "#         lowerLimit = np.array([hue - 10, 100, 100], dtype=np.uint8)\n",
    "#         upperLimit = np.array([180, 255, 255], dtype=np.uint8)\n",
    "#     elif hue <= 15:  # Lower limit for divided red hue\n",
    "#         lowerLimit = np.array([0, 100, 100], dtype=np.uint8)\n",
    "#         upperLimit = np.array([hue + 10, 255, 255], dtype=np.uint8)\n",
    "#     else:\n",
    "#         lowerLimit = np.array([hue - 10, 100, 100], dtype=np.uint8)\n",
    "#         upperLimit = np.array([hue + 10, 255, 255], dtype=np.uint8)\n",
    "\n",
    "#     return lowerLimit, upperLimit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frame = cv2.imread('colors.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yellow = [0,255,255]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cap = cv.VideoCapture(2)\n",
    "# while True:\n",
    "#     ret, frame = cap.read()\n",
    "    \n",
    "\n",
    "#     hsvimg = cv.cvtColor(frame, cv.COLOR_BGR2HSV)\n",
    "#     lowerLimit, upperLimit = get_limits(color=yellow)\n",
    "#     mask = cv.inRange(hsvimg, lowerLimit, upperLimit)\n",
    "#     mask_ = Image.fromarray(mask)\n",
    "#     bbox = mask_.getbbox()\n",
    "#     if bbox is not None:\n",
    "#         x1, y1, x2, y2 = bbox\n",
    "\n",
    "#         frame = cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 5)\n",
    "\n",
    "#     cv.imshow('frame', frame)\n",
    "\n",
    "#     if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "#         break\n",
    "\n",
    "# cap.release()\n",
    "# cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hsvimg = cv.cvtColor(img, cv.COLOR_BGR2HSV)\n",
    "# lowerLimit, upperLimit = get_limits(color=yellow)\n",
    "# mask = cv.inRange(hsvimg, lowerLimit, upperLimit)\n",
    "# mask_ = Image.fromarray(mask)\n",
    "# bbox = mask_.getbbox()\n",
    "# if bbox is not None:\n",
    "#     x1, y1, x2, y2 = bbox\n",
    "\n",
    "#     frame = cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 5)\n",
    "\n",
    "\n",
    "# cv2.imshow('img', img)\n",
    "# cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hsvImage = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# lowerLimit, upperLimit = get_limits(color=yellow)\n",
    "\n",
    "# mask = cv2.inRange(hsvImage, lowerLimit, upperLimit)\n",
    "\n",
    "# contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# for contour in contours:\n",
    "#     area = cv2.contourArea(contour)\n",
    "#     if area > 100: \n",
    "#         x, y, w, h = cv2.boundingRect(contour)\n",
    "#         cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "# cv2.imshow('frame', frame)\n",
    "\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2: face anonymizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [],
   "source": [
    "face1 = './face1.png'\n",
    "face2 = './face2.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(face1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [],
   "source": [
    "H,W,_ = img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_face_detection = mp.solutions.face_detection\n",
    "\n",
    "with mp_face_detection.FaceDetection(model_selection=0, min_detection_confidence=0.5) as face_detection:\n",
    "    img_rgb = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "    out = face_detection.process(img_rgb)\n",
    "\n",
    "    if out.detections is not None:\n",
    "        for detection in out.detections:\n",
    "            location_data = detection.location_data\n",
    "            bbox = location_data.relative_bounding_box\n",
    "\n",
    "            x1, y1, w, h = bbox.xmin, bbox.ymin, bbox.width, bbox.height\n",
    "\n",
    "            x1 = int(x1*W)\n",
    "            y1 = int(y1*H)\n",
    "            w = int(w*W)\n",
    "            h = int(h*H)\n",
    "\n",
    "            # img = cv.rectangle(img, (x1,y1), (x1 + w, y1+h), (0,255,0), 10)\n",
    "            img[y1:y1 + h, x1:x1 + w, :] = cv2.blur(img[y1:y1 + h, x1:x1 + w, :], (60, 60))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 589,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.imshow('img', img)\n",
    "cv.waitKey(0)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
